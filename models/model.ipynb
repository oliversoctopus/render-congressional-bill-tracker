{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22f40241-19a7-4449-b530-275ee7129d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TIME-AWARE MODEL TRAINING\n",
      "============================================================\n",
      "Using 118th_enhanced dataset\n",
      "Loaded 16565 bills\n",
      "Passed bills: 274 (1.7%)\n",
      "\n",
      "============================================================\n",
      "CREATING VIABILITY TARGET\n",
      "============================================================\n",
      "Viable bills: 3364 (20.3%)\n",
      "\n",
      "Creating enhanced features...\n",
      "\n",
      "======================================================================\n",
      "PHASE 1: VIABILITY PREDICTION\n",
      "======================================================================\n",
      "\n",
      "============================================================\n",
      "TRAINING VIABILITY MODELS\n",
      "============================================================\n",
      "\n",
      "--- Training new_bill model ---\n",
      "Using 15 features\n",
      "Positive class rate: 20.3%\n",
      "Selected top 14 features\n",
      "Training individual models...\n",
      "Training ensemble model...\n",
      "Calibrating probabilities...\n",
      "\n",
      "Performance (threshold=0.500):\n",
      "  Accuracy: 0.8071\n",
      "  ROC-AUC: 0.7679\n",
      "  Precision: 0.5746\n",
      "  Recall: 0.1947\n",
      "  F1 Score: 0.2908\n",
      "  CV ROC-AUC: 0.7626 (+/- 0.0264)\n",
      "\n",
      "Top 5 features:\n",
      "  - policy_area_encoded: 0.1612\n",
      "  - title_complexity: 0.1035\n",
      "  - has_bipartisan_support: 0.1007\n",
      "  - party_dominance: 0.0994\n",
      "  - bipartisan_score: 0.0968\n",
      "\n",
      "--- Training early_stage model ---\n",
      "Using 22 features\n",
      "Positive class rate: 20.3%\n",
      "Selected top 20 features\n",
      "Training individual models...\n",
      "Training ensemble model...\n",
      "Calibrating probabilities...\n",
      "\n",
      "Performance (threshold=0.500):\n",
      "  Accuracy: 0.8171\n",
      "  ROC-AUC: 0.7746\n",
      "  Precision: 0.6516\n",
      "  Recall: 0.2140\n",
      "  F1 Score: 0.3221\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 403\u001b[39m\n\u001b[32m    401\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPHASE 1: VIABILITY PREDICTION\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    402\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m70\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m403\u001b[39m viability_models = \u001b[43mtrain_robust_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mviable\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mViability\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_sets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[38;5;66;03m# Train passage models on viable bills only\u001b[39;00m\n\u001b[32m    406\u001b[39m viable_bills = df[df[\u001b[33m'\u001b[39m\u001b[33mviable\u001b[39m\u001b[33m'\u001b[39m] == \u001b[32m1\u001b[39m].copy()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 349\u001b[39m, in \u001b[36mtrain_robust_model\u001b[39m\u001b[34m(df, target_col, model_name, feature_sets, use_calibration)\u001b[39m\n\u001b[32m    346\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  F1 at 0.5 threshold: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf1_default\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    348\u001b[39m \u001b[38;5;66;03m# Cross-validation for robustness check\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m349\u001b[39m cv_scores = \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensemble\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_selected\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStratifiedKFold\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mroc_auc\u001b[39;49m\u001b[33;43m'\u001b[39;49m\n\u001b[32m    353\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  CV ROC-AUC: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcv_scores.mean()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (+/- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcv_scores.std()*\u001b[32m2\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    356\u001b[39m \u001b[38;5;66;03m# Store model components\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Projects\\predictive-bill-tracker\\env\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    212\u001b[39m         skip_parameter_validation=(\n\u001b[32m    213\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    214\u001b[39m         )\n\u001b[32m    215\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    222\u001b[39m     msg = re.sub(\n\u001b[32m    223\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Projects\\predictive-bill-tracker\\env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:684\u001b[39m, in \u001b[36mcross_val_score\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, error_score)\u001b[39m\n\u001b[32m    681\u001b[39m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[32m    682\u001b[39m scorer = check_scoring(estimator, scoring=scoring)\n\u001b[32m--> \u001b[39m\u001b[32m684\u001b[39m cv_results = \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    685\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    687\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mscore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    691\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    692\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    693\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    694\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    695\u001b[39m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[33m\"\u001b[39m\u001b[33mtest_score\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Projects\\predictive-bill-tracker\\env\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    212\u001b[39m         skip_parameter_validation=(\n\u001b[32m    213\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    214\u001b[39m         )\n\u001b[32m    215\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    222\u001b[39m     msg = re.sub(\n\u001b[32m    223\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Projects\\predictive-bill-tracker\\env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:411\u001b[39m, in \u001b[36mcross_validate\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[39m\n\u001b[32m    408\u001b[39m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[32m    409\u001b[39m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[32m    410\u001b[39m parallel = Parallel(n_jobs=n_jobs, verbose=verbose, pre_dispatch=pre_dispatch)\n\u001b[32m--> \u001b[39m\u001b[32m411\u001b[39m results = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    412\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    415\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    417\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    418\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    419\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    420\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    422\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    423\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    424\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    425\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    426\u001b[39m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    427\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    428\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[32m    429\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    431\u001b[39m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[32m    433\u001b[39m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[32m    434\u001b[39m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[32m    435\u001b[39m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Projects\\predictive-bill-tracker\\env\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Projects\\predictive-bill-tracker\\env\\Lib\\site-packages\\joblib\\parallel.py:1986\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1984\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1985\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1986\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1988\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1989\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1990\u001b[39m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1991\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1992\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1993\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Projects\\predictive-bill-tracker\\env\\Lib\\site-packages\\joblib\\parallel.py:1914\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1913\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1915\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1916\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Projects\\predictive-bill-tracker\\env\\Lib\\site-packages\\sklearn\\utils\\parallel.py:139\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    137\u001b[39m     config = {}\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config):\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Projects\\predictive-bill-tracker\\env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:866\u001b[39m, in \u001b[36m_fit_and_score\u001b[39m\u001b[34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[39m\n\u001b[32m    864\u001b[39m         estimator.fit(X_train, **fit_params)\n\u001b[32m    865\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m866\u001b[39m         \u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[32m    870\u001b[39m     fit_time = time.time() - start_time\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Projects\\predictive-bill-tracker\\env\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Projects\\predictive-bill-tracker\\env\\Lib\\site-packages\\sklearn\\utils\\validation.py:63\u001b[39m, in \u001b[36m_deprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     61\u001b[39m extra_args = \u001b[38;5;28mlen\u001b[39m(args) - \u001b[38;5;28mlen\u001b[39m(all_args)\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m extra_args <= \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# extra_args > 0\u001b[39;00m\n\u001b[32m     66\u001b[39m args_msg = [\n\u001b[32m     67\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(name, arg)\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m name, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(kwonly_args[:extra_args], args[-extra_args:])\n\u001b[32m     69\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Projects\\predictive-bill-tracker\\env\\Lib\\site-packages\\sklearn\\ensemble\\_voting.py:419\u001b[39m, in \u001b[36mVotingClassifier.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, **fit_params)\u001b[39m\n\u001b[32m    416\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    417\u001b[39m     fit_params[\u001b[33m\"\u001b[39m\u001b[33msample_weight\u001b[39m\u001b[33m\"\u001b[39m] = sample_weight\n\u001b[32m--> \u001b[39m\u001b[32m419\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransformed_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Projects\\predictive-bill-tracker\\env\\Lib\\site-packages\\sklearn\\ensemble\\_voting.py:100\u001b[39m, in \u001b[36m_BaseVoting.fit\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m     95\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33msample_weight\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m fit_params:\n\u001b[32m     96\u001b[39m             routed_params[name].fit[\u001b[33m\"\u001b[39m\u001b[33msample_weight\u001b[39m\u001b[33m\"\u001b[39m] = fit_params[\n\u001b[32m     97\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33msample_weight\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     98\u001b[39m             ]\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m \u001b[38;5;28mself\u001b[39m.estimators_ = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_single_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfit\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mVoting\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclfs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclfs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclf\u001b[49m\u001b[43m \u001b[49m\u001b[43m!=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdrop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m    111\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    113\u001b[39m \u001b[38;5;28mself\u001b[39m.named_estimators_ = Bunch()\n\u001b[32m    115\u001b[39m \u001b[38;5;66;03m# Uses 'drop' as placeholder for dropped estimators\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Projects\\predictive-bill-tracker\\env\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Projects\\predictive-bill-tracker\\env\\Lib\\site-packages\\joblib\\parallel.py:1986\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1984\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1985\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1986\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1988\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1989\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1990\u001b[39m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1991\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1992\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1993\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Projects\\predictive-bill-tracker\\env\\Lib\\site-packages\\joblib\\parallel.py:1914\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1913\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1915\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1916\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Projects\\predictive-bill-tracker\\env\\Lib\\site-packages\\sklearn\\utils\\parallel.py:139\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    137\u001b[39m     config = {}\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config):\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Projects\\predictive-bill-tracker\\env\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:39\u001b[39m, in \u001b[36m_fit_single_estimator\u001b[39m\u001b[34m(estimator, X, y, fit_params, message_clsname, message)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     38\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m         \u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m estimator\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Projects\\predictive-bill-tracker\\env\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Projects\\predictive-bill-tracker\\env\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:487\u001b[39m, in \u001b[36mBaseForest.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    476\u001b[39m trees = [\n\u001b[32m    477\u001b[39m     \u001b[38;5;28mself\u001b[39m._make_estimator(append=\u001b[38;5;28;01mFalse\u001b[39;00m, random_state=random_state)\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[32m    479\u001b[39m ]\n\u001b[32m    481\u001b[39m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[32m    482\u001b[39m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[32m    483\u001b[39m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[32m    484\u001b[39m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[32m    485\u001b[39m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[32m    486\u001b[39m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m487\u001b[39m trees = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mthreads\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    503\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    505\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    506\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    508\u001b[39m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[32m    509\u001b[39m \u001b[38;5;28mself\u001b[39m.estimators_.extend(trees)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Projects\\predictive-bill-tracker\\env\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Projects\\predictive-bill-tracker\\env\\Lib\\site-packages\\joblib\\parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Projects\\predictive-bill-tracker\\env\\Lib\\site-packages\\joblib\\parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Projects\\predictive-bill-tracker\\env\\Lib\\site-packages\\joblib\\parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# TIME-AWARE DUAL MODEL APPROACH\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, PolynomialFeatures\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix, precision_recall_curve\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TIME-AWARE MODEL TRAINING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load data\n",
    "available_datasets = {}\n",
    "if os.path.exists('../data/bills_118th_congress_training_enhanced.csv'):\n",
    "    available_datasets = {'118th_enhanced': '../data/bills_118th_congress_training_enhanced.csv'}\n",
    "else:\n",
    "    print(\"ERROR: No dataset found.\")\n",
    "    raise FileNotFoundError\n",
    "dataset_path = list(available_datasets.values())[0]\n",
    "dataset_name = list(available_datasets.keys())[0]\n",
    "\n",
    "print(f\"Using {dataset_name} dataset\")\n",
    "\n",
    "df = pd.read_csv(dataset_path)\n",
    "print(f\"Loaded {len(df)} bills\")\n",
    "print(f\"Passed bills: {df['passed'].sum()} ({df['passed'].mean()*100:.1f}%)\")\n",
    "\n",
    "# Viability definition\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CREATING VIABILITY TARGET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Balanced viability criteria - aim for ~15-20% viable\n",
    "df['viable'] = (\n",
    "    (df['passed'] == 1) |  # Passed\n",
    "    ((df.get('action_count', 0) >= 6) & (df.get('committee_count', 0) >= 1)) |  # Good activity + committee\n",
    "    ((df.get('cosponsor_count', 0) >= 30) & (df.get('action_count', 0) >= 4)) |  # Strong support + some activity\n",
    "    ((df.get('action_count', 0) >= 10)) |  # Very high activity alone\n",
    "    (df.get('failure_reason', '') == 'failed_to_complete')  # Almost passed\n",
    ").astype(int)\n",
    "\n",
    "# Add milestone-based viability\n",
    "if 'latest_action' in df.columns:\n",
    "    strong_milestones = ['passed', 'reported', 'ordered reported', 'markup', 'hearing held']\n",
    "    pattern = '|'.join(strong_milestones)\n",
    "    df['has_strong_milestone'] = df['latest_action'].fillna('').str.lower().str.contains(pattern)\n",
    "    df['viable'] = df['viable'] | df['has_strong_milestone']\n",
    "    df['viable'] = df['viable'].astype(int)\n",
    "\n",
    "print(f\"Viable bills: {df['viable'].sum()} ({df['viable'].mean()*100:.1f}%)\")\n",
    "\n",
    "# Feature engineering\n",
    "print(\"\\nCreating enhanced features...\")\n",
    "\n",
    "# Fill missing values with sensible defaults\n",
    "df['sponsor_party'] = df['sponsor_party'].fillna('Unknown')\n",
    "df['policy_area'] = df['policy_area'].fillna('Unknown')\n",
    "df['days_since_introduction'] = df.get('days_since_introduction', 30).fillna(30).clip(1, 730)\n",
    "df['action_count'] = df.get('action_count', 1).fillna(1).clip(1, 100)\n",
    "df['committee_count'] = df.get('committee_count', 0).fillna(0)\n",
    "df['cosponsor_count'] = df.get('cosponsor_count', 0).fillna(0)\n",
    "df['original_cosponsor_count'] = df.get('original_cosponsor_count', 0).fillna(0)\n",
    "\n",
    "# Label encoding\n",
    "le_party = LabelEncoder()\n",
    "df['sponsor_party_encoded'] = le_party.fit_transform(df['sponsor_party'])\n",
    "\n",
    "le_policy = LabelEncoder()\n",
    "df['policy_area_encoded'] = le_policy.fit_transform(df['policy_area'])\n",
    "\n",
    "# Enhanced feature engineering\n",
    "# Basic sponsor features\n",
    "df['dem_sponsors'] = df.get('dem_sponsors', 0).fillna(0)\n",
    "df['rep_sponsors'] = df.get('rep_sponsors', 0).fillna(0)\n",
    "df['ind_sponsors'] = df.get('ind_sponsors', 0).fillna(0)\n",
    "df['dem_cosponsors'] = df.get('dem_cosponsors', 0).fillna(0)\n",
    "df['rep_cosponsors'] = df.get('rep_cosponsors', 0).fillna(0)\n",
    "\n",
    "df['sponsor_count'] = (df['dem_sponsors'] + df['rep_sponsors'] + df['ind_sponsors']).clip(1, 10)\n",
    "df['total_sponsors'] = df['sponsor_count'] + df['cosponsor_count']\n",
    "\n",
    "# Party balance features\n",
    "df['dem_total'] = df['dem_sponsors'] + df['dem_cosponsors']\n",
    "df['rep_total'] = df['rep_sponsors'] + df['rep_cosponsors']\n",
    "df['party_balance'] = (df['dem_total'] - df['rep_total']) / (df['total_sponsors'] + 1)\n",
    "df['party_dominance'] = abs(df['party_balance'])\n",
    "\n",
    "# Bipartisan features\n",
    "df['bipartisan_score'] = 1 - df['party_dominance']\n",
    "df['has_bipartisan_support'] = ((df['dem_total'] > 0) & (df['rep_total'] > 0)).astype(int)\n",
    "\n",
    "# Temporal features - more robust\n",
    "df['month_introduced'] = df.get('month_introduced', datetime.now().month).fillna(datetime.now().month)\n",
    "df['quarter_introduced'] = ((df['month_introduced'] - 1) // 3 + 1).astype(int)\n",
    "df['is_election_year'] = df.get('is_election_year', 0).fillna(0)\n",
    "\n",
    "# Text features\n",
    "df['title_length'] = df.get('title_length', 100).fillna(100).clip(10, 500)\n",
    "df['title_word_count'] = df.get('title_word_count', 20).fillna(20).clip(2, 100)\n",
    "df['title_complexity'] = df['title_length'] / (df['title_word_count'] + 1)\n",
    "\n",
    "# Subject features\n",
    "df['subject_count'] = df.get('subject_count', 1).fillna(1).clip(1, 20)\n",
    "\n",
    "# Time-aware features with better scaling\n",
    "df['days_active'] = df['days_since_introduction'].clip(1, 730)\n",
    "df['log_days_active'] = np.log1p(df['days_active'])\n",
    "df['sqrt_days_active'] = np.sqrt(df['days_active'])\n",
    "\n",
    "# Activity features - normalized\n",
    "df['activity_rate'] = df['action_count'] / df['days_active']\n",
    "df['normalized_activity'] = df['action_count'] / np.log1p(df['days_active'])\n",
    "df['early_activity'] = df['action_count'] / (df['days_active'].clip(upper=30) + 1)\n",
    "\n",
    "# Momentum features\n",
    "df['is_fresh'] = (df['days_active'] <= 30).astype(int)\n",
    "df['is_active'] = (df['days_active'] <= 90).astype(int)\n",
    "df['is_stale'] = (df['days_active'] > 180).astype(int)\n",
    "\n",
    "# Committee features\n",
    "df['committee_density'] = df['committee_count'] / (df['days_active'] / 30).clip(lower=1)\n",
    "df['has_committee'] = (df['committee_count'] > 0).astype(int)\n",
    "df['multi_committee'] = (df['committee_count'] >= 2).astype(int)\n",
    "\n",
    "# Support growth features\n",
    "df['cosponsor_growth'] = (df['cosponsor_count'] - df['original_cosponsor_count']) / (df['days_active'] / 30).clip(lower=1)\n",
    "df['support_velocity'] = df['total_sponsors'] / np.sqrt(df['days_active'])\n",
    "\n",
    "# Interaction features\n",
    "df['bipartisan_momentum'] = df['bipartisan_score'] * df['normalized_activity']\n",
    "df['committee_activity'] = df['committee_count'] * df['activity_rate']\n",
    "\n",
    "# Define feature sets with overlapping features for smoother transitions\n",
    "base_features = [\n",
    "    'sponsor_party_encoded',\n",
    "    'sponsor_count',\n",
    "    'original_cosponsor_count',\n",
    "    'month_introduced',\n",
    "    'quarter_introduced',\n",
    "    'is_election_year',\n",
    "    'title_length',\n",
    "    'title_word_count',\n",
    "    'title_complexity',\n",
    "    'subject_count',\n",
    "    'policy_area_encoded',\n",
    "    'party_balance',\n",
    "    'party_dominance',\n",
    "    'bipartisan_score',\n",
    "    'has_bipartisan_support'\n",
    "]\n",
    "\n",
    "# Additional features for models with more information\n",
    "extended_features = base_features + [\n",
    "    'cosponsor_count',\n",
    "    'total_sponsors',\n",
    "    'is_fresh',\n",
    "    'support_velocity',\n",
    "    'cosponsor_growth',\n",
    "    'dem_total',\n",
    "    'rep_total'\n",
    "]\n",
    "\n",
    "progressive_features = extended_features + [\n",
    "    'days_active',\n",
    "    'log_days_active',\n",
    "    'activity_rate',\n",
    "    'normalized_activity',\n",
    "    'is_active',\n",
    "    'is_stale',\n",
    "    'committee_count',\n",
    "    'has_committee',\n",
    "    'multi_committee',\n",
    "    'committee_density',\n",
    "    'action_count',\n",
    "    'early_activity',\n",
    "    'bipartisan_momentum',\n",
    "    'committee_activity'\n",
    "]\n",
    "\n",
    "# Model training function with improved methodology\n",
    "def train_robust_model(df, target_col, model_name, feature_sets, use_calibration=True):\n",
    "    \"\"\"Train models with better methodology\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"TRAINING {model_name.upper()} MODELS\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    models = {}\n",
    "    \n",
    "    for stage_name, features in feature_sets.items():\n",
    "        print(f\"\\n--- Training {stage_name} model ---\")\n",
    "        \n",
    "        # Filter available features\n",
    "        available_features = [f for f in features if f in df.columns]\n",
    "        print(f\"Using {len(available_features)} features\")\n",
    "        \n",
    "        # Prepare data\n",
    "        X = df[available_features].fillna(0)\n",
    "        X = X.replace([np.inf, -np.inf], 0)\n",
    "        y = df[target_col]\n",
    "        \n",
    "        # Check class distribution\n",
    "        pos_rate = y.mean()\n",
    "        print(f\"Positive class rate: {pos_rate:.1%}\")\n",
    "        \n",
    "        # Split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42, stratify=y\n",
    "        )\n",
    "        \n",
    "        # Scale features\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = pd.DataFrame(\n",
    "            scaler.fit_transform(X_train),\n",
    "            columns=X_train.columns,\n",
    "            index=X_train.index\n",
    "        )\n",
    "        X_test_scaled = pd.DataFrame(\n",
    "            scaler.transform(X_test),\n",
    "            columns=X_test.columns,\n",
    "            index=X_test.index\n",
    "        )\n",
    "        \n",
    "        # Feature selection - use mutual information for better feature selection\n",
    "        k_features = min(20, len(available_features) - 1)\n",
    "        selector = SelectKBest(mutual_info_classif, k=k_features)\n",
    "        selector.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        selected_indices = selector.get_support(indices=True)\n",
    "        selected_features = [available_features[i] for i in selected_indices]\n",
    "        \n",
    "        X_train_selected = X_train_scaled[selected_features]\n",
    "        X_test_selected = X_test_scaled[selected_features]\n",
    "        \n",
    "        print(f\"Selected top {k_features} features\")\n",
    "        \n",
    "        # Create diverse ensemble\n",
    "        # 1. Random Forest with balanced weights\n",
    "        rf_model = RandomForestClassifier(\n",
    "            n_estimators=300,\n",
    "            max_depth=15,\n",
    "            min_samples_split=20,\n",
    "            min_samples_leaf=10,\n",
    "            class_weight='balanced_subsample',\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        # 2. Gradient Boosting with careful tuning\n",
    "        gb_model = GradientBoostingClassifier(\n",
    "            n_estimators=200,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=5,\n",
    "            subsample=0.8,\n",
    "            min_samples_split=20,\n",
    "            min_samples_leaf=10,\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        # 3. Logistic Regression for stable predictions\n",
    "        lr_model = LogisticRegression(\n",
    "            class_weight='balanced',\n",
    "            max_iter=1000,\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        # Train individual models first\n",
    "        print(\"Training individual models...\")\n",
    "        rf_model.fit(X_train_selected, y_train)\n",
    "        gb_model.fit(X_train_selected, y_train)\n",
    "        lr_model.fit(X_train_selected, y_train)\n",
    "        \n",
    "        # Create voting ensemble\n",
    "        ensemble = VotingClassifier(\n",
    "            estimators=[\n",
    "                ('rf', rf_model),\n",
    "                ('gb', gb_model),\n",
    "                ('lr', lr_model)\n",
    "            ],\n",
    "            voting='soft',\n",
    "            weights=[0.4, 0.4, 0.2]  # Weight trees more than linear\n",
    "        )\n",
    "        \n",
    "        # Train ensemble\n",
    "        print(\"Training ensemble model...\")\n",
    "        ensemble.fit(X_train_selected, y_train)\n",
    "        \n",
    "        # Calibrate probabilities if requested\n",
    "        if use_calibration and pos_rate < 0.3:\n",
    "            print(\"Calibrating probabilities...\")\n",
    "            calibrated_ensemble = CalibratedClassifierCV(\n",
    "                ensemble, \n",
    "                method='isotonic',\n",
    "                cv=3\n",
    "            )\n",
    "            calibrated_ensemble.fit(X_train_selected, y_train)\n",
    "            final_model = calibrated_ensemble\n",
    "        else:\n",
    "            final_model = ensemble\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred_proba = final_model.predict_proba(X_test_selected)[:, 1]\n",
    "        \n",
    "        # Use adaptive threshold based on class balance\n",
    "        # For imbalanced data, use a lower threshold\n",
    "        if pos_rate < 0.15:  # Very imbalanced\n",
    "            threshold = pos_rate * 2  # More lenient threshold\n",
    "        else:\n",
    "            threshold = 0.5\n",
    "        \n",
    "        y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "        \n",
    "        # Calculate metrics with adaptive threshold\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        \n",
    "        # Calculate precision and recall\n",
    "        from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "        precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "        recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "        \n",
    "        # Also calculate metrics at default threshold for comparison\n",
    "        y_pred_default = (y_pred_proba >= 0.5).astype(int)\n",
    "        f1_default = f1_score(y_test, y_pred_default, zero_division=0)\n",
    "        \n",
    "        print(f\"\\nPerformance (threshold={threshold:.3f}):\")\n",
    "        print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"  ROC-AUC: {roc_auc:.4f}\")\n",
    "        print(f\"  Precision: {precision:.4f}\")\n",
    "        print(f\"  Recall: {recall:.4f}\")\n",
    "        print(f\"  F1 Score: {f1:.4f}\")\n",
    "        if threshold != 0.5:\n",
    "            print(f\"  F1 at 0.5 threshold: {f1_default:.4f}\")\n",
    "        \n",
    "        # Cross-validation for robustness check\n",
    "        cv_scores = cross_val_score(\n",
    "            ensemble, X_train_selected, y_train, \n",
    "            cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "            scoring='roc_auc'\n",
    "        )\n",
    "        print(f\"  CV ROC-AUC: {cv_scores.mean():.4f} (+/- {cv_scores.std()*2:.4f})\")\n",
    "        \n",
    "        # Store model components\n",
    "        models[stage_name] = {\n",
    "            'model': final_model,\n",
    "            'ensemble': ensemble,\n",
    "            'rf_model': rf_model,\n",
    "            'gb_model': gb_model,\n",
    "            'lr_model': lr_model,\n",
    "            'scaler': scaler,\n",
    "            'selector': selector,\n",
    "            'features': available_features,\n",
    "            'selected_features': selected_features,\n",
    "            'threshold': threshold,\n",
    "            'performance': {\n",
    "                'accuracy': accuracy,\n",
    "                'roc_auc': roc_auc,\n",
    "                'precision': precision,\n",
    "                'recall': recall,\n",
    "                'f1_score': f1,\n",
    "                'cv_roc_auc': cv_scores.mean(),\n",
    "                'cv_std': cv_scores.std()\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Feature importance analysis\n",
    "        if hasattr(rf_model, 'feature_importances_'):\n",
    "            importance_df = pd.DataFrame({\n",
    "                'feature': selected_features,\n",
    "                'importance': rf_model.feature_importances_\n",
    "            }).sort_values('importance', ascending=False)\n",
    "            \n",
    "            print(f\"\\nTop 5 features:\")\n",
    "            for _, row in importance_df.head(5).iterrows():\n",
    "                print(f\"  - {row['feature']}: {row['importance']:.4f}\")\n",
    "    \n",
    "    return models\n",
    "\n",
    "# Define feature sets\n",
    "feature_sets = {\n",
    "    'new_bill': base_features,\n",
    "    'early_stage': extended_features,\n",
    "    'progressive': progressive_features\n",
    "}\n",
    "\n",
    "# Train viability models\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PHASE 1: VIABILITY PREDICTION\")\n",
    "print(\"=\"*70)\n",
    "viability_models = train_robust_model(df, 'viable', 'Viability', feature_sets)\n",
    "\n",
    "# Train passage models on viable bills only\n",
    "viable_bills = df[df['viable'] == 1].copy()\n",
    "print(f\"\\n\" + \"=\"*70)\n",
    "print(f\"PHASE 2: PASSAGE PREDICTION\")\n",
    "print(f\"Training on {len(viable_bills)} viable bills ({viable_bills['passed'].mean():.1%} passed)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "passage_models = train_robust_model(viable_bills, 'passed', 'Passage', feature_sets)\n",
    "\n",
    "# Model evaluation on different bill stages\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL EVALUATION BY BILL AGE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for days_threshold, stage_name in [(1, 'Brand New'), (30, 'Early Stage'), (180, 'Progressive')]:\n",
    "    if days_threshold == 1:\n",
    "        stage_bills = df[df['days_active'] <= days_threshold]\n",
    "        model_key = 'new_bill'\n",
    "    elif days_threshold == 30:\n",
    "        stage_bills = df[(df['days_active'] > 1) & (df['days_active'] <= days_threshold)]\n",
    "        model_key = 'early_stage'\n",
    "    else:\n",
    "        stage_bills = df[df['days_active'] > 30]\n",
    "        model_key = 'progressive'\n",
    "    \n",
    "    if len(stage_bills) > 0:\n",
    "        print(f\"\\n{stage_name} Bills (n={len(stage_bills)}):\")\n",
    "        print(f\"  Viability rate: {stage_bills['viable'].mean():.1%}\")\n",
    "        print(f\"  Passage rate: {stage_bills['passed'].mean():.1%}\")\n",
    "        print(f\"  Model ROC-AUC: {viability_models[model_key]['performance']['roc_auc']:.4f}\")\n",
    "\n",
    "# Create models directory if it doesn't exist\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# Save models in logical groups\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SAVING MODELS IN ORGANIZED FILES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Save metadata and encoders (this stays the same)\n",
    "metadata = {\n",
    "    'training_date': datetime.now().isoformat(),\n",
    "    'dataset_size': len(df),\n",
    "    'viable_rate': df['viable'].mean(),\n",
    "    'passage_rate': df['passed'].mean(),\n",
    "    'model_version': '3.0',\n",
    "    'improvements': [\n",
    "        'Conservative thresholds (0.5)',\n",
    "        'Ensemble with calibration',\n",
    "        'Mutual information feature selection',\n",
    "        'Better handling of class imbalance',\n",
    "        'More robust features for early bills'\n",
    "    ],\n",
    "    'feature_sets': feature_sets  # Make sure feature_sets is included here\n",
    "}\n",
    "\n",
    "joblib.dump({\n",
    "    'metadata': metadata,\n",
    "    'label_encoders': {\n",
    "        'party': le_party,\n",
    "        'policy': le_policy\n",
    "    }\n",
    "}, 'models/metadata.pkl')\n",
    "print(\" Saved metadata.pkl\")\n",
    "\n",
    "# Save viability models - one file per stage\n",
    "for stage_name, model_data in viability_models.items():\n",
    "    # Combine all stage-specific viability models into one file\n",
    "    stage_package = {\n",
    "        'rf_model': model_data['rf_model'],\n",
    "        'gb_model': model_data['gb_model'],\n",
    "        'lr_model': model_data['lr_model'],\n",
    "        'ensemble': model_data['ensemble'],\n",
    "        'final_model': model_data['model'],\n",
    "        'scaler': model_data['scaler'],\n",
    "        'selector': model_data['selector'],\n",
    "        'features': model_data['features'],\n",
    "        'selected_features': model_data['selected_features'],\n",
    "        'threshold': model_data['threshold'],\n",
    "        'performance': model_data['performance']\n",
    "    }\n",
    "    \n",
    "    filename = f'models/viability_{stage_name}.pkl'\n",
    "    joblib.dump(stage_package, filename)\n",
    "    \n",
    "    # Check file size\n",
    "    size_mb = os.path.getsize(filename) / (1024 * 1024)\n",
    "    print(f\" Saved {filename} ({size_mb:.1f} MB)\")\n",
    "\n",
    "# Save passage models - one file per stage\n",
    "for stage_name, model_data in passage_models.items():\n",
    "    # Combine all stage-specific passage models into one file\n",
    "    stage_package = {\n",
    "        'rf_model': model_data['rf_model'],\n",
    "        'gb_model': model_data['gb_model'],\n",
    "        'lr_model': model_data['lr_model'],\n",
    "        'ensemble': model_data['ensemble'],\n",
    "        'final_model': model_data['model'],\n",
    "        'scaler': model_data['scaler'],\n",
    "        'selector': model_data['selector'],\n",
    "        'features': model_data['features'],\n",
    "        'selected_features': model_data['selected_features'],\n",
    "        'threshold': model_data['threshold'],\n",
    "        'performance': model_data['performance']\n",
    "    }\n",
    "    \n",
    "    filename = f'models/passage_{stage_name}.pkl'\n",
    "    joblib.dump(stage_package, filename)\n",
    "    \n",
    "    # Check file size\n",
    "    size_mb = os.path.getsize(filename) / (1024 * 1024)\n",
    "    print(f\" Saved {filename} ({size_mb:.1f} MB)\")\n",
    "\n",
    "# List all saved files and their sizes\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL FILE SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "total_size = 0\n",
    "file_count = 0\n",
    "for file in sorted(os.listdir('models')):\n",
    "    if file.endswith('.pkl'):\n",
    "        file_path = os.path.join('models', file)\n",
    "        size_mb = os.path.getsize(file_path) / (1024 * 1024)\n",
    "        total_size += size_mb\n",
    "        file_count += 1\n",
    "        \n",
    "        # Describe what each file contains\n",
    "        if file == 'metadata.pkl':\n",
    "            desc = \"Training metadata and label encoders\"\n",
    "        elif 'viability' in file:\n",
    "            stage = file.replace('viability_', '').replace('.pkl', '')\n",
    "            desc = f\"All viability models for {stage.replace('_', ' ')} bills\"\n",
    "        elif 'passage' in file:\n",
    "            stage = file.replace('passage_', '').replace('.pkl', '')\n",
    "            desc = f\"All passage models for {stage.replace('_', ' ')} bills\"\n",
    "        else:\n",
    "            desc = \"Model file\"\n",
    "            \n",
    "        print(f\"{file:<30} {size_mb:>6.1f} MB  - {desc}\")\n",
    "\n",
    "print(f\"\\nTotal: {file_count} files, {total_size:.1f} MB\")\n",
    "print(f\"All files under 100 MB \" if all(os.path.getsize(os.path.join('models', f)) < 100*1024*1024 for f in os.listdir('models') if f.endswith('.pkl')) else \"WARNING: Some files exceed 100 MB!\")\n",
    "\n",
    "# Test predictions with confidence intervals\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SAMPLE PREDICTIONS WITH CONFIDENCE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get a few test bills\n",
    "test_bills = df.sample(5, random_state=42)\n",
    "\n",
    "for _, bill in test_bills.iterrows():\n",
    "    # Determine model stage\n",
    "    if bill['days_active'] <= 1:\n",
    "        model_key = 'new_bill'\n",
    "    elif bill['days_active'] <= 30:\n",
    "        model_key = 'early_stage'\n",
    "    else:\n",
    "        model_key = 'progressive'\n",
    "    \n",
    "    # Get features\n",
    "    viability_model = viability_models[model_key]\n",
    "    features = viability_model['features']\n",
    "    \n",
    "    # Prepare data\n",
    "    bill_features = bill[features].values.reshape(1, -1)\n",
    "    bill_features = np.nan_to_num(bill_features, 0)\n",
    "    \n",
    "    # Scale and select\n",
    "    bill_scaled = viability_model['scaler'].transform(bill_features)\n",
    "    bill_selected = bill_scaled[:, viability_model['selector'].get_support()]\n",
    "    \n",
    "    # Get prediction with individual model predictions for confidence\n",
    "    viability_proba = viability_model['model'].predict_proba(bill_selected)[0, 1]\n",
    "    \n",
    "    # Get individual model predictions for confidence range\n",
    "    rf_proba = viability_model['rf_model'].predict_proba(bill_selected)[0, 1]\n",
    "    gb_proba = viability_model['gb_model'].predict_proba(bill_selected)[0, 1]\n",
    "    lr_proba = viability_model['lr_model'].predict_proba(bill_selected)[0, 1]\n",
    "    \n",
    "    probas = [rf_proba, gb_proba, lr_proba]\n",
    "    confidence_low = min(probas)\n",
    "    confidence_high = max(probas)\n",
    "    \n",
    "    print(f\"\\nBill: {bill.get('bill_id', 'Unknown')} (Day {int(bill['days_active'])})\")\n",
    "    print(f\"  Actual: Viable={bill['viable']}, Passed={bill['passed']}\")\n",
    "    print(f\"  Model: {model_key}\")\n",
    "    print(f\"  Viability: {viability_proba:.1%} (range: {confidence_low:.1%}-{confidence_high:.1%})\")\n",
    "    print(f\"  Confidence spread: {(confidence_high - confidence_low):.1%}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL TRAINING COMPLETE!\")\n",
    "print(\"Models saved in 'models' directory as separate files\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b7d404-ae48-4011-9893-8e7387a89429",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
